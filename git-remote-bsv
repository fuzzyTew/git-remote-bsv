#!/usr/bin/env node

const child_process = require('child_process')
const crypto = require('crypto')
const glob = require('glob')
const path = require('path')
const readline = require('readline')
const fse = require('fs-extra')

const bitfiles = require('bitfiles')
const bsv = require('bsv')
const bsvup = require('bsvup')

var FETCH_SITE = (process.env.BSV_GATEWAY || 'https://bico.media').replace('://', '::') // '::' instead of '://' informs git the server has no git cgi
if (FETCH_SITE.slice(-1) !== '/') FETCH_SITE += '/'
const GIT_DIR = path.resolve(process.env.GIT_DIR || child_process.spawnSync('git', ['rev-parse', '--git-dir']).stdout.toString().replace('\n', ''))
const fork_glob = path.join(GIT_DIR, 'bsv', '*', 'git.*')
const DISTINGUISHING_TEXT = 'This is a git-remote-bsv D:// web repository.'

if (process.argv.length < 3 || process.argv[2] === '-h' || process.argv[2] === '--help') {
  const key = bsv.PrivateKey()
  process.stderr.write('\nNew key pair generated in memory.\n')
  process.stderr.write('  Send coins to: ' + key.toAddress().toString() + '\n')
  process.stderr.write('\n')
  process.stderr.write('To make a push remote to the new key pair:\n')
  process.stderr.write('  git remote add bsv bsv://' + key.toString() + '/path/to/repo.git\n')
  process.stderr.write('To make a fetch-only remote to the new key pair:\n')
  process.stderr.write('  git remote add bsv bsv://' + key.toAddress().toString() + '/path/to/repo.git\n')
  process.stderr.write('\n')
  process.stderr.write('To list forks of the current repo:\n')
  process.stderr.write('  git remote-bsv --forks\n')
  process.stderr.write('To list repos on the blockchain:\n')
  process.stderr.write('  git remote-bsv --repos\n')
  process.stderr.write('\n')
  process.exit(0)
} else if (process.argv.length === 3 && (process.argv[2] === '-r' || process.argv[2] === '--repos')) {
  findrepos()
} else if (process.argv.length === 3 && (process.argv[2] === '-f' || process.argv[2] === '--forks')) {
  findforks()
} else {
  remote()
}

function remote () {
  const remotename = process.argv[3] ? process.argv[2] : undefined
  const origurl = remotename ? process.argv[3] : process.argv[2]
  var url = origurl
  url = url.replace('bsv://', '')
  url = url.replace('https://', '')
  url = url.replace('http://', '')
  url = url.replace('bico.media/', '')
  url = url + '/'
  url = url.replace(/\/\/+/g, '/')

  const urlparts = url.split('/')
  const subkey = urlparts.slice(1).join('/')
  var addr = urlparts[0]
  var privkey = undefined
  if (bsv.PrivateKey.isValid(addr)) {
    privkey = addr
    addr = bsv.PrivateKey(privkey).toAddress().toString()
    urlparts[0] = addr
    url = urlparts.join('/')
    if (remotename) {
      if (child_process.spawnSync('git', ['config', '--get', 'remote.' + remotename + '.pushurl']).stdout.length === 0) {
        child_process.spawnSync('git', ['remote', 'set-url', '--push', remotename, origurl])
        child_process.spawnSync('git', ['remote', 'set-url', remotename, origurl.replace(privkey, addr)])
      }
    }
  }

  const bsv_path = path.join(GIT_DIR, 'bsv', addr)
  const mirror_path = path.join(bsv_path, 'git.' + crypto.createHash('sha256').update(urlparts.join(path.sep)).digest('hex'))
  const mirror_path_new = path.join(bsv_path, 'git.new')

  const lines = readline.createInterface({
    input: process.stdin
  })

  lines.on('line', (line) => {
    if (line === 'capabilities') {
      process.stdout.write('connect\n\n')
    } else if (line.substr(0, 8) === 'connect ') {
      const service = line.substr(8)
      connect(service).catch(err => {
        process.stderr.write(err + '\n')
        process.exit(-1)
      })
    }
  })

  async function connect (service) {
    console.log = text=>process.stderr.write(`${text}\n`)
    if (service === 'git-upload-pack') {
      await download()
    } else if (service === 'git-receive-pack') {
      if (!privkey) {
        process.stderr.write('Url not recognized as private key to upload to\n')
        process.exit(-1)
      }
      try {
        await download()
      } catch (e) {
        if (!fse.existsSync(mirror_path)) {
          const res = child_process.spawnSync('git', ['init', '--bare', mirror_path], { stdio: [null, 2, 2], env: {} })
          if (res.status !== 0) process.exit(res.status)
          for (const file of glob.sync(path.join(fork_glob, 'objects', 'pack', '*'))) {
            try {
              fse.copyFileSync(file, path.join(mirror_path, 'objects', 'pack', path.basename(file)), fse.constants.COPYFILE_EXCL)
            } catch (e) {}
          }
        }
      }
      const res = child_process.spawnSync('git', ['config', 'gc.auto', 0], { stdio: [null, 2, 2], env: { GIT_DIR: mirror_path } })
      if (res.status !== 0) process.exit(res.status)
    } else {
      process.stderr.write('Unsupported service: ' + service + '\n')
      process.exit(-1)
    }
    process.stdout.write('\n')
    const res = child_process.spawnSync(service, [mirror_path], { stdio: 'inherit', cwd: mirror_path })
    if (res.status !== 0) process.exit(res.status)
    if (service === 'git-receive-pack') {
      await upload()
    }
  }

  async function download () {
    const fetchurl = FETCH_SITE + url
    var res
    if (!fse.existsSync(path.join(mirror_path, 'HEAD'))) {
      fse.ensureDirSync(mirror_path)
      res = child_process.spawnSync('git', ['clone', '--bare', '--mirror', fetchurl, mirror_path], { cwd: mirror_path, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path } })
    } else {
      res = child_process.spawnSync('git', ['fetch', '--tags', fetchurl, '+refs/*:refs/*'], { cwd: mirror_path, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path } })
    }
    //if (res.status !== 0) throw new Error('Failed to fetch')
    process.chdir(mirror_path)
    await bitfiles.ddownload(addr, subkey + 'objects')
    await bitfiles.ddownload(addr, subkey + 'info')
    await bitfiles.ddownload(addr, subkey + 'refs')
    await bitfiles.ddownload(addr, subkey + 'HEAD')
    await bitfiles.ddownload(addr, subkey + 'packed-refs')
    res = child_process.spawnSync('git', ['config', 'gc.auto', 0], { stdio: [null, 2, 2], env: { GIT_DIR: mirror_path } })
    if (res.status !== 0) throw new Error('Failed to disable GC')
  }

  async function upload () {
    if (fse.existsSync(mirror_path_new)) {
      fse.removeSync(mirror_path_new)
    }
    child_process.spawnSync('git', ['clone', '--mirror', '--bare', mirror_path, mirror_path_new], { stdio: [null, 2, 2], env: {} })
    child_process.spawnSync('git', ['config', 'gc.auto', 0], { cwd: mirror_path_new, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path_new } })
    child_process.spawnSync('git', ['pack-objects', '--all', '--include-tag', '--unpacked', '--incremental', '--non-empty', '--local', '--progress', '--compression=9', '--delta-base-offset', '--pack-loose-unreachable', 'objects/pack/pack'], { cwd: mirror_path_new, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path_new } })
    child_process.spawnSync('git', ['prune-packed'], { cwd: mirror_path_new, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path_new } })
    const first_commit = child_process.spawnSync('git', ['rev-list', '--max-parents=0', 'HEAD'], { cwd: mirror_path_new, env: { GIT_DIR: mirror_path_new } }).stdout.toString().replace('\n', '')
    child_process.spawnSync('git', ['tag', url.replace(':', '/').replace(/\/\/*/, '/'), first_commit], { cwd: mirror_path_new, env: { GIT_DIR: mirror_path_new } })
    child_process.spawnSync('git', ['update-server-info'], { cwd: mirror_path_new, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path_new } })
    fse.writeFileSync(path.join(mirror_path_new, 'git-remote-bsv'), DISTINGUISHING_TEXT)
    fse.copyFileSync(path.join(GIT_DIR, 'description'), path.join(mirror_path_new, 'description'))
    let cwd = process.cwd()
    process.chdir(bsv_path)
    //bsvup.api.setLogLevel(bsvup.api.logLevel.INFO)
    bsvup.cache.initCache()
    try {
      let utxos = await bsvup.api.getUTXOs(addr)
      let starting_satoshis = utxos.reduce((totalProvided, utxo) => totalProvided += utxo.amount ? Math.round(utxo.amount * 1e8) : utxo.satoshis, 0)
      process.stderr.write(`${addr} wallet balance: ${starting_satoshis} satoshis\n`)
      let tasks = await bsvup.logic.prepareUpload(mirror_path_new, bsv.PrivateKey(privkey), null, subkey)
      if (tasks.length === 0) throw new Error(`No changes to upload.  If this is an obscure error, you could try wiping ${mirror_path}`)
      let price_satoshis = tasks.reduce((totalRequired, task) => totalRequired += Math.max(bsvup.txUtil.parameters.DUST_LIMIT, task.satoshis + Math.ceil(178*250/1000)), 0)
      process.stderr.write(`Upload price: ${price_satoshis} satoshis\n`)
      process.stderr.write(`Balance after upload: ${starting_satoshis - price_satoshis} satoshis\n`)
      process.stderr.write(`Uploading these files:\n`)
      tasks.filter(task => task.type === 'D').forEach(task => {
        process.stderr.write(` https://bico.media/${addr}/${task.out.key}\n`)
      })
      let txs = bsvup.logic.getTXs(tasks)
      bsvup.cache.saveUnbroadcast(txs)
      while (true) {
        process.stderr.write(`Broadcasting ${txs.length} transactions ...\n`)
        txs = await bsvup.api.tryBroadcastAll()
        if (!txs.length) { break }
        process.stderr.write(`Not all transactions broadcast. ${txs.length} are cached and will be rebroadcast in 120s.\n`)
        await new Promise(resolve => setTimeout(resolve, 120000))
      }

      // success
      process.stderr.write('upload succeeded\n')
      fse.removeSync(mirror_path)
      fse.renameSync(mirror_path_new, mirror_path)
    } catch(e) {
      // failure
      if (e.message === 'Insuffient satoshis.') {
         process.stderr.write('Send to ' + addr + '\n')
      }
      process.stderr.write('upload failed: ' + e + '\n')
      fse.removeSync(mirror_path_new)
      process.exit(-1)
    }
  }
}

async function findforks () {
  // find root commit // TODO: all branches?
  const commits = child_process.spawnSync('git', ['rev-list', '--max-parents=0', 'HEAD']).stdout.toString().split('\n').filter(cmt => cmt !== '')
  const sha256s = {}

  // add sha256sums for tags of root commits
  for (const commit of commits) {
    sha256s[commit] = crypto.createHash('sha256').update(commit + '\n').digest('hex')
  }

  // enumerate packfiles to find packfiles containing root commit
  for (const file of glob.sync(path.join(fork_glob, 'objects', 'pack', '*'))) {
    const bname = path.basename(file)
    if (bname in sha256s) continue
    for (let gitobj of child_process.spawnSync('git', ['verify-pack', '-v', file]).stdout.toString().split('\n')) {
      gitobj = gitobj.split(' ')
      if (gitobj[1] !== 'commit') continue
      if (commits.includes(gitobj[0])) {
        // this packfile has the root commit in it.
        // take sha256sum of packfile
        const hash = crypto.createHash('sha256').update(fse.readFileSync(file)).digest('hex')
        sha256s[bname] = hash
        break
      }
    }
  }
  await findReposWithFiles(sha256s, /\/refs\/tags\/[^\/]*$|\/objects\/pack\/pack-[^\/]*$/)
}

async function findrepos()
{
  const sha256s = {}
  sha256s['git-remote-bsv'] = crypto.createHash('sha256').update(DISTINGUISHING_TEXT).digest('hex')
  sha256s['description'] = crypto.createHash('sha256').update("Unnamed repository; edit this file 'description' to name the repository.\n").digest('hex')
  sha256s['post-update.sample'] = "81765af2daef323061dcbc5e61fc16481cb74b3bac9ad8a174b186523586f6c5"
  await findReposWithFiles(sha256s, /\/hooks\/post-update\.sample$|\/git-remote-bsv$|\/description$/)
}

async function findReposWithFiles(sha256s, pathregexp)
{
  // lookup B:// addresses of sha256s
  // make our own query by copying bitdb.js from bsvup
  // below works better after changing genesis to data
  const bitdbd = 'https://data.bitdb.network/q/1KuUr2pSJDao97XM8Jsq8zwLS6W1WtFfLg/'
  const BitDBKey = '1Px8CKdrfJUw7eVrTmVYjYtmtDoxjD6tGt'
  const fetch = require('node-fetch')
  const Bquery = {
    v: 3,
    q: {
      find: { },
      project: {
        tx: 1
      }
    },
    r: {
      f: '[ .[] | .tx.h ]'
    }
  }
  let Baddrs = new Set()
  for (const key in sha256s) {
    Bquery.q.find.c = sha256s[key]
    // console.log(JSON.stringify(Bquery))
    const b64 = Buffer.from(JSON.stringify(Bquery)).toString('base64')
    const url = bitdbd + b64
    // console.log(url)
    const header = { headers: { key: BitDBKey } }
    let res = await fetch(url, header)
    res = await res.json()
    res = res.u.concat(res.c)
    // console.log(res) // res is now an array of B:// addresses
    Baddrs = new Set(res.concat(...Baddrs))
  }
  // console.log("B:// addresses containing pack or tag for this repo:")
  // console.log(Baddrs)

  // lookup D:// addresses of files from B:// addresses
  const bitdbg = 'https://genesis.bitdb.network/q/1FnauZ9aUH2Bex6JzdcV4eNX7oLSSEbxtN/'
  const Dquery = {
    v: 3,
    q: {
      find: {
        'out.s1': '19iG3WTYSsbyos3uJ733yK4zEioi1FesNU',
        'out.s4': 'b'
      }
    },
    r: {
      f: '[ .[] | { addr: .in[0].e.a, key: .out[0].s2 } ]'
    }
  }
  let forks = new Set()
  for (const Baddr of Baddrs) {
    Dquery.q.find['out.s3'] = Baddr
    const b64 = Buffer.from(JSON.stringify(Dquery)).toString('base64')
    const url = bitdbg + b64
    // console.log(url)
    const header = { headers: { key: BitDBKey } }
    let res = await fetch(url, header)
    res = await res.json()
    res = res.u.concat(res.c)
    // console.log(res)
    // for each path, remove either refs/tags/.*?^ or objects/pack/pack-.*?^
    res = res.map(x =>
      (x.addr + '/' + x.key)
        .replace(pathregexp, '')
    )
    forks = new Set(res.concat(...forks))
  }
  for (const fork of forks) {
    const descrurl = FETCH_SITE.replace('::','://') + fork + '/description'
    let descr = await fetch(descrurl)
    if (descr.ok) {
      descr = await descr.text()
      descr = descr.replace(/\n.*$/,'')
    } else {
      descr = '<failed to fetch GIT_DIR/description>'
    }
    console.log('bsv://' + fork + '\t' + descr)
  }
}


