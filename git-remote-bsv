#!/usr/bin/env node

// TODO: FIX HIGH FEE.  network supports down to 250 but the server used by bsvup may not support that.
feePerKb = 500

const child_process = require('child_process')
const crypto = require('crypto')
const glob = require('glob')
const path = require('path')
const readline = require('readline')
const fse = require('fs-extra')

const bitfiles = require('bitfiles')
const bsv = require('bsv')
const bsvup = require('bsvup')

const GIT_DIR = path.resolve(process.env.GIT_DIR || child_process.spawnSync('git', ['rev-parse', '--git-dir']).stdout.toString().replace('\n', ''))
const fork_glob = path.join(GIT_DIR, 'bsv', '*', 'git.*')
const DISTINGUISHING_TEXT = 'This is a git-remote-bsv D:// web repository.'
const DEFAULT_DESCRIPTION = 'Unnamed repository; edit this file \'description\' to name the repository.\n'

if (process.argv.length < 3 || process.argv[2] === '-h' || process.argv[2] === '--help') {
  const key = bsv.PrivateKey()
  process.stderr.write('\nNew key pair generated in memory.\n')
  process.stderr.write('  Send coins to: ' + key.toAddress().toString() + '\n')
  process.stderr.write('\n')
  process.stderr.write('To make a push remote to the new key pair:\n')
  process.stderr.write('  git remote add bsv bsv://' + key.toString() + '/path/to/repo.git\n')
  process.stderr.write('To make a fetch-only remote to the new key pair:\n')
  process.stderr.write('  git remote add bsv bsv://' + key.toAddress().toString() + '/path/to/repo.git\n')
  process.stderr.write('\n')
  process.stderr.write('To list forks of the current repo:\n')
  process.stderr.write('  git remote-bsv --forks\n')
  process.stderr.write('To list repos on the blockchain:\n')
  process.stderr.write('  git remote-bsv --repos\n')
  process.stderr.write('\n')
  process.exit(0)
} else if (process.argv.length === 3 && (process.argv[2] === '-r' || process.argv[2] === '--repos')) {
  findrepos()
} else if (process.argv.length === 3 && (process.argv[2] === '-f' || process.argv[2] === '--forks')) {
  findforks()
} else {
  remote()
}

function remote () {
  const remotename = process.argv[3] ? process.argv[2] : undefined
  const origurl = remotename ? process.argv[3] : process.argv[2]
  var url = origurl
  url = url.replace('bsv://', '')
  url = url.replace('https://', '')
  url = url.replace('http://', '')
  url = url.replace('bico.media/', '')
  url = url + '/'
  url = url.replace(/\/\/+/g, '/')

  const urlparts = url.split('/')
  const subkey = urlparts.slice(1).join('/')
  var addr = urlparts[0]
  var privkey = undefined
  if (bsv.PrivateKey.isValid(addr)) {
    privkey = addr
    addr = bsv.PrivateKey(privkey).toAddress().toString()
    urlparts[0] = addr
    url = urlparts.join('/')
    if (remotename) {
      if (child_process.spawnSync('git', ['config', '--get', 'remote.' + remotename + '.pushurl']).stdout.length === 0) {
        child_process.spawnSync('git', ['remote', 'set-url', '--push', remotename, origurl])
        child_process.spawnSync('git', ['remote', 'set-url', remotename, origurl.replace(privkey, addr)])
      }
    }
  }

  const bsv_path = path.join(GIT_DIR, 'bsv', addr)
  const mirror_path = path.join(bsv_path, 'git.' + crypto.createHash('sha256').update(urlparts.join(path.sep)).digest('hex'))
  const mirror_path_new = path.join(bsv_path, 'git.new')

  const lines = readline.createInterface({
    input: process.stdin
  })

  lines.on('line', (line) => {
    if (line === 'capabilities') {
      process.stdout.write('connect\n\n')
    } else if (line.substr(0, 8) === 'connect ') {
      const service = line.substr(8)
      connect(service).catch(err => {
        process.stderr.write(err + '\n')
        process.exit(-1)
      })
    }
  })

  async function connect (service) {
    console.log = text=>process.stderr.write(`${text}\n`)
    if (service === 'git-upload-pack') {
      await download()
    } else if (service === 'git-receive-pack') {
      if (!privkey) {
        process.stderr.write('Url not recognized as private key to upload to\n')
        process.exit(-1)
      }
      try {
        await download()
      } catch (e) {
        if (!fse.existsSync(mirror_path + "/refs")) {
          const res = child_process.spawnSync('git', ['init', '--bare', mirror_path], { stdio: [null, 2, 2], env: {} })
          if (res.status !== 0) process.exit(res.status)
          for (const file of glob.sync(path.join(fork_glob, 'objects', 'pack', '*'))) {
            try {
              fse.copyFileSync(file, path.join(mirror_path, 'objects', 'pack', path.basename(file)), fse.constants.COPYFILE_EXCL)
            } catch (e) {}
          }
        }
      }
      const res = child_process.spawnSync('git', ['config', 'gc.auto', 0], { stdio: [null, 2, 2], env: { GIT_DIR: mirror_path } })
      if (res.status !== 0) process.exit(res.status)
    } else {
      process.stderr.write('Unsupported service: ' + service + '\n')
      process.exit(-1)
    }
    process.stdout.write('\n')
    const res = child_process.spawnSync(service, [mirror_path], { stdio: 'inherit', cwd: mirror_path })
    if (res.status !== 0) process.exit(res.status)
    if (service === 'git-receive-pack') {
      await upload()
    }
  }

  async function download () {
    fse.ensureDirSync(mirror_path)
    process.chdir(mirror_path)
    await bitfiles.ddownload(addr, subkey + 'description')
    await bitfiles.ddownload(addr, subkey + 'config')
    await bitfiles.ddownload(addr, subkey + 'objects', true, true)
    await bitfiles.ddownload(addr, subkey + 'info')
    await bitfiles.ddownload(addr, subkey + 'refs')
    await bitfiles.ddownload(addr, subkey + 'HEAD')
    await bitfiles.ddownload(addr, subkey + 'packed-refs')
    fse.ensureDirSync(mirror_path + '/refs')
    res = child_process.spawnSync('git', ['config', 'gc.auto', 0], { stdio: [null, 2, 2], env: { GIT_DIR: mirror_path } })
    if (res.status !== 0) {
      fse.removeSync(mirror_path + '/refs')
      throw new Error('Failed to disable GC')
    }
    if (fse.existsSync(path.join(mirror_path, 'description'))) {
      if (!fse.existsSync(path.join(GIT_DIR, 'description')) || fse.readFileSync(path.join(GIT_DIR, 'description')) == DEFAULT_DESCRIPTION) {
        fse.copyFileSync(path.join(mirror_path, 'description'), path.join(GIT_DIR, 'description'))
      }
    }
  }

  async function upload () {
    if (fse.existsSync(mirror_path_new)) {
      fse.removeSync(mirror_path_new)
    }
    child_process.spawnSync('git', ['clone', '--mirror', '--bare', mirror_path, mirror_path_new], { stdio: [null, 2, 2], env: {} })
    child_process.spawnSync('git', ['config', 'gc.auto', 0], { cwd: mirror_path_new, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path_new } })
    child_process.spawnSync('git', ['pack-objects', '--all', '--include-tag', '--unpacked', '--incremental', '--non-empty', '--local', '--progress', '--compression=9', '--delta-base-offset', '--pack-loose-unreachable', 'objects/pack/pack'], { cwd: mirror_path_new, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path_new } })
    child_process.spawnSync('git', ['prune-packed'], { cwd: mirror_path_new, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path_new } })
    const first_commit = child_process.spawnSync('git', ['rev-list', '--max-parents=0', 'HEAD'], { cwd: mirror_path_new, env: { GIT_DIR: mirror_path_new } }).stdout.toString().replace('\n', '')
    child_process.spawnSync('git', ['tag', url.replace(':', '/').replace(/\/\/*/, '/'), first_commit], { cwd: mirror_path_new, env: { GIT_DIR: mirror_path_new } }) //*///<- comment-termination fixes syntax hilighting on some editors, due to /* appearing in line
    child_process.spawnSync('git', ['update-server-info'], { cwd: mirror_path_new, stdio: [null, 2, 2], env: { GIT_DIR: mirror_path_new } })
    fse.writeFileSync(path.join(mirror_path_new, 'git-remote-bsv'), DISTINGUISHING_TEXT)
    if (!fse.existsSync(path.join(mirror_path, 'description')) || fse.readFileSync(path.join(GIT_DIR, 'description')) != DEFAULT_DESCRIPTION) {
      fse.copyFileSync(path.join(GIT_DIR, 'description'), path.join(mirror_path_new, 'description'))
    }
    let cwd = process.cwd()
    process.chdir(bsv_path)
    bsvup.api.setLogLevel(bsvup.api.logLevel.INFO)
    bsvup.cache.initCache()
    try {
      let utxos = await bsvup.api.getUTXOs(addr)
      let starting_satoshis = utxos.reduce((totalProvided, utxo) => totalProvided += utxo.amount ? Math.round(utxo.amount * 1e8) : utxo.satoshis, 0)
      process.stderr.write(`${addr} wallet balance: ${starting_satoshis} satoshis\n`)
      let tasks = await bsvup.logic.prepareUpload(mirror_path_new, bsv.PrivateKey(privkey), null, subkey, feePerKb)
      if (tasks.length === 0) throw new Error(`No changes to upload.  If this is an obscure error, you could try wiping ${mirror_path}`)
      let price_satoshis = tasks.reduce((totalRequired, task) => totalRequired += Math.max(bsvup.txUtil.parameters.DUST_LIMIT, task.satoshis + Math.ceil(178*250/1000)), 0)
      process.stderr.write(`Upload price: ${price_satoshis} satoshis\n`)
      process.stderr.write(`Balance after upload: ${starting_satoshis - price_satoshis} satoshis\n`)
      process.stderr.write(`Uploading these files:\n`)
      tasks.filter(task => task.type === 'D').forEach(task => {
        process.stderr.write(` https://bico.media/${addr}/${task.out.key}\n`)
      })
      let txs = bsvup.logic.getTXs(tasks)
      bsvup.cache.saveUnbroadcast(txs)
      while (true) {
        process.stderr.write(`Broadcasting ${txs.length} transactions ...\n`)
        txs = await bsvup.api.tryBroadcastAll()
        if (!txs.length) { break }
        process.stderr.write(`Not all transactions broadcast. ${txs.length} are cached and will be rebroadcast in 120s.\n`)
        await new Promise(resolve => setTimeout(resolve, 120000))
      }

      // success
      process.stderr.write('upload succeeded\n')
      fse.removeSync(mirror_path)
      fse.renameSync(mirror_path_new, mirror_path)
    } catch(e) {
      // failure
      if (e.message === 'Insuffient satoshis.') {
         process.stderr.write('Send to ' + addr + '\n')
      }
      process.stderr.write('upload failed: ' + e + '\n')
      fse.removeSync(mirror_path_new)
      process.exit(-1)
    }
  }
}

async function findforks () {
  // find root commit // TODO: all branches?
  const commits = child_process.spawnSync('git', ['rev-list', '--max-parents=0', 'HEAD']).stdout.toString().split('\n').filter(cmt => cmt !== '')
  const sha256s = {}

  // add sha256sums for tags of root commits
  for (const commit of commits) {
    sha256s[commit] = {
      content: commit + '\n',
      sha256: crypto.createHash('sha256').update(commit + '\n').digest('hex')
    }
  }

  // enumerate packfiles to find packfiles containing root commit
  for (const file of glob.sync(path.join(fork_glob, 'objects', 'pack', '*'))) {
    const bname = path.basename(file)
    if (bname in sha256s) continue
    for (let gitobj of child_process.spawnSync('git', ['verify-pack', '-v', file]).stdout.toString().split('\n')) {
      gitobj = gitobj.split(' ')
      if (gitobj[1] !== 'commit') continue
      if (commits.includes(gitobj[0])) {
        // this packfile has the root commit in it.
        // take sha256sum of packfile
        const content = fse.readFileSync(file)
        const hash = crypto.createHash('sha256').update(content).digest('hex')
        sha256s[bname] = {
          content: content.length <= 512 ? content : undefined,
          sha256: hash
        }
        break
      }
    }
  }
  await findReposWithFiles(sha256s, /\/refs\/tags\/.*$|\/objects\/pack\/pack-[^\/]*$/)
}

async function findrepos()
{
  const sha256s = {}
  sha256s['git-remote-bsv'] = {
    content: DISTINGUISHING_TEXT,
    sha256: crypto.createHash('sha256').update(DISTINGUISHING_TEXT).digest('hex')
  }
  sha256s['description'] = {
    content: DEFAULT_DESCRIPTION,
    sha256: crypto.createHash('sha256').update(DEFAULT_DESCRIPTION).digest('hex')
  }
  sha256s['post-update.sample'] = {
    content: '#!/bin/sh\n#\n# An example hook script to prepare a packed repository for use over\n# dumb transports.\n#\n# To enable this hook, rename this file to "post-update".\n\nexec git update-server-info\n',
    sha256: "81765af2daef323061dcbc5e61fc16481cb74b3bac9ad8a174b186523586f6c5"
  }
  await findReposWithFiles(sha256s, /\/hooks\/post-update\.sample$|\/git-remote-bsv$|\/description$/)
}

async function findReposWithFiles(sha256s, pathregexp)
{
  // this was hacked together quickly by copying from bsvup, bitfiles, bsv atlantis chat
  
  // lookup B:// addresses of sha256s
  // uses ctxt.planaria.network
  const ctxt = 'https://ctxt.planaria.network/txt/'
  const limit = 100
  const cparams = '/json?limit=' + limit + '&offset='
  const fetch = require('node-fetch')
  let Baddrs = new Set()
  for (const key in sha256s) {
    offset = 0
    while (true) {
      const url = ctxt + sha256s[key].sha256 + cparams + offset
      // console.log(url)
      let res = await fetch(url)
      res = await res.json()
      res = res.result.map(x => x.tx_id)
      // console.log(res) // res is now an array of B:// addresses
      Baddrs = new Set(res.concat(...Baddrs))
      if (res.length < limit) { break; }
    }
  }
  // console.log("B:// addresses containing pack or tag for this repo:")
  // console.log(Baddrs)

  // lookup B:// addresses of small files from their content directly as ctxt uses bitfs which only indexes above 512 bytes
  const BitDBKey = '1Px8CKdrfJUw7eVrTmVYjYtmtDoxjD6tGt'
  const bitdbg = 'https://genesis.bitdb.network/q/1FnauZ9aUH2Bex6JzdcV4eNX7oLSSEbxtN/'
  const Bquery = {
    v: 3,
    q: {
      find: {
        '$or': [
          { 'out.s1': '19HxigV4QyBv3tHpQVcUEQyq1pzZVdoAut' },
          { 'out.s2': '19HxigV4QyBv3tHpQVcUEQyq1pzZVdoAut' }
        ]
      },
      project: {
        tx: 1
      }
    }
  }
  for (const key in sha256s) {
    let content = sha256s[key].content
    if (!content || content.length > 512) {
      delete sha256s[key].content
      continue
    }
    Bquery.q.find['$or'][0]['out.s2'] = content
    Bquery.q.find['$or'][1]['out.s3'] = content
    const b64 = Buffer.from(JSON.stringify(Bquery)).toString('base64')
    const url = bitdbg + b64
    const header = { headers: { key: BitDBKey } }
    let res = await fetch(url, header)
    res = await res.json()
    res = res.u.concat(res.c).map(entry => entry.tx.h)
    Baddrs = new Set(res.concat(...Baddrs))
  }
  // lookup D:// addresses of files from B:// addresses
  const Dquery = {
    v: 3,
    q: {
      find: {
        '$or': [
          {
            'out.s1': '19iG3WTYSsbyos3uJ733yK4zEioi1FesNU',
            'out.s4': 'b'
          }, {
            'out.s2': '19iG3WTYSsbyos3uJ733yK4zEioi1FesNU',
            'out.s5': 'b'
          }
        ]
      }
    }
  }
  let forks = new Set()
  for (const Baddr of Baddrs) {
    Dquery.q.find['$or'][0]['out.s3'] = Baddr
    Dquery.q.find['$or'][1]['out.s4'] = Baddr
    const b64 = Buffer.from(JSON.stringify(Dquery)).toString('base64')
    const url = bitdbg + b64
    // console.log(url)
    const header = { headers: { key: BitDBKey } }
    let res = await fetch(url, header)
    res = await res.json()
    res = res.u.concat(res.c)
    // console.log(res)
    // for each path, remove either refs/tags/.*?^ or objects/pack/pack-.*?^
    res = res.map(x => {
      const key = x.out[0].s1 ? x.out[0].s2 : x.out[0].s3
      const path = x.in[0].e.a + '/' + key
      return path.replace(pathregexp, '')
    })
    forks = new Set(res.concat(...forks))
  }
  for (const fork of forks) {
    let parts = fork.split('/')
    let addr = parts.shift()
    let subkey = parts.join('/')
    let descr
    try {
      descr = await bitfiles.d(addr, subkey ? subkey + '/description' : 'description')
      descr = descr.toString()
      descr = descr.replace(/\n.*$/,'')
    } catch (exception) {
      descr = '<failed to fetch GIT_DIR/description>'
    }
    console.log('bsv://' + fork + '\t' + descr)
  }
}


